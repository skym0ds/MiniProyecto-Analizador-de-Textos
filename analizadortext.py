
#Importaci칩n de librer칤as
import nltk #Liber칤a principal para el procesamiento del lenguaje natural
from nltk.corpus import wordnet as wn, stopwords
from nltk import word_tokenize, pos_tag, ne_chunk, FreqDist
import tkinter as tk
from tkinter import filedialog, scrolledtext, messagebox


def analizar_texto(texto):
    resultado = ""

    if not texto.strip():
        return "丘멆잺 No se ha ingresado texto"

#Tokenizaci칩n
#Se divide el texto en una lista de palabras (tokens) y se convierten a min칰sculas.
    tokens = word_tokenize(texto.lower(), language="spanish")

#Liempieza, solo se tomar치n las palabras (sin signos ni n칰meros) y se eliminar치n las stopwords (palabras vac칤as)
    tokens_limpios = [t for t in tokens if t.isalpha()]

# Se carga el conjunto de "stopwords" (palabras comunes sin valor sem치ntico) en espa침ol.

    stop_words = set(stopwords.words("spanish"))
    tokens_filtrados = [t for t in tokens_limpios if t not in stop_words]

#N칰mero de palabras reales
    num_palabras = len(tokens_filtrados)  #Se corrigi칩 y se agreg칩 la filtraci칩n para contar palabras "reales"
    resultado += f"游늷 N칰mero total de palabras: {num_palabras}\n\n"

#Frecuencia de t칠rminos
    fdist = FreqDist(tokens_filtrados)
    top_terminos = fdist.most_common(5)
    resultado += "游늷 T칠rminos clave m치s comunes:\n"
    for palabra, frecuencia in top_terminos:
        resultado += f"{palabra}: {frecuencia}\n"
    resultado += "\n"

#Sin칩nimos para los t칠rminos clave
    resultado += "游늷 Sin칩nimos de los t칠rminos clave:\n"
    for palabra, _ in top_terminos:
        synsets = wn.synsets(palabra, lang="spa") #Se busca la palabra en wordnet
        sinonimos = set() #Evitamos sin칩nimos duplicados
        for syn in synsets:
            for lemma in syn.lemmas("spa"):
                sinonimos.add(lemma.name())
        if sinonimos:
            resultado += f"- {palabra}: {', '.join(list(sinonimos)[:5])}\n" #Se proporcionan los primeros 5 resultados
        else:
            resultado += f"- {palabra}: (no se encontraron sin칩nimos)\n"
    resultado += "\n"

#Reconocimiento de Entidades Nombradas (NER)
    tokens_origen = word_tokenize(texto, language="spanish") #se agreg칩 el idioma a espa침ol
    etiquetas = pos_tag(tokens_origen)     # Primero, se etiqueta cada palabra con su categor칤a gramatical (nombre, verbo, adjetivo, etc.)
    arbol_entidades = ne_chunk(etiquetas) #agrupa las palabras con su categor칤a gramatical
    resultado += "游늷 Entidades reconocidas en el texto:\n"
    for subtree in arbol_entidades:
        if hasattr(subtree, "label"):
            entidad = " ".join(c[0] for c in subtree.leaves())
            resultado += f"{subtree.label()}: {entidad}\n"

    return resultado


#Funci칩n para bot칩n "Analizar"
def ejecutar_analisis():
    texto = entrada_texto.get("1.0", tk.END)
    try:
        resultado = analizar_texto(texto)
        salida_texto.delete("1.0", tk.END)
        salida_texto.insert(tk.END, resultado)
    except Exception as e:
        messagebox.showerror("Error en an치lisis", str(e))


#Funci칩n para cargar archivo txt
def cargar_archivo():
    archivo = filedialog.askopenfilename(filetypes=[("Archivos de texto", "*.txt")])
    if archivo:
        try:
            with open(archivo, "r", encoding="utf-8") as f:
                contenido = f.read()
                entrada_texto.delete("1.0", tk.END)
                entrada_texto.insert(tk.END, contenido)
        except Exception as e:
            messagebox.showerror("Error", f"No se pudo abrir el archivo: {e}")

#Funci칩n para limpiar o borrar el texto introducido
def limpiar_texto():
    entrada_texto.delete("1.0", tk.END)
    salida_texto.delete("1.0", tk.END)



#Interfaz gr치fica (Tkinter)
ventana = tk.Tk()
ventana.title("Analizador de Textos Academicos Equipo 11")
ventana.geometry("850x650")

#Etiqueta
tk.Label(ventana, text="Introduce un texto acad칠mico o carga un archivo .txt:",
         font=("Arial", 12)).pack(pady=5)

#Cuadro de texto para entrada
entrada_texto = scrolledtext.ScrolledText(ventana, wrap=tk.WORD, width=95, height=10)
entrada_texto.pack(padx=10, pady=10)

#Botones
frame_botones = tk.Frame(ventana)
frame_botones.pack()

btn_analizar = tk.Button(frame_botones, text="Analizar", command=ejecutar_analisis, bg="lightgreen")
btn_analizar.grid(row=0, column=0, padx=5)

btn_cargar = tk.Button(frame_botones, text="Cargar archivo .txt", command=cargar_archivo, bg="lightblue")
btn_cargar.grid(row=0, column=1, padx=5)

btn_limpiar = tk.Button(frame_botones, text="Limpiar", command=limpiar_texto, bg="salmon")
btn_limpiar.grid(row=0, column=2, padx=5)

#Cuadro de texto para salida
tk.Label(ventana, text="Resultados del an치lisis:",
         font=("Arial", 12)).pack(pady=5)

salida_texto = scrolledtext.ScrolledText(ventana, wrap=tk.WORD, width=95, height=20, state="normal")
salida_texto.pack(padx=10, pady=10)

ventana.mainloop()
